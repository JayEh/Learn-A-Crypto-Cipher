{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can we learn a simple cipher?**\n",
    "\n",
    "In the AES Cipher notebook we saw that it was not possible to learn an AES cipher with a small LSTM and a few training samples. In this notebook we'll try the same test but with a very simple cipher that uses a key and replacement. Please know ahead of time I know nothing about cryptography and this should be seen as a toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from solution2 import get_random_pairs, encode, decode, get_model, get_alphabet, encode_output\n",
    "from simple_cipher import AotWCipher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the training data**\n",
    "\n",
    "Here the cipher object is created and used to create some training data. The data into the model will be int encoded so I can try using an embedding, and the output is one hot encoded. At this step we have the raw text and cipher encoded text and a few examples are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key:  11\n",
      "Generated 250000 encrpyted sequences.\n",
      "Example of origin and encrypted text:\n",
      "\toD:W3+i\n",
      "\t[ 32  11  95  89  80 118  56]\n",
      "Example of origin and encrypted text:\n",
      "\tja^B+7))s\n",
      "\t[ 51  59  63 109 128  77  94 150  73]\n",
      "Example of origin and encrypted text:\n",
      "\t$9agC\n",
      "\t[13 29 83 67 77]\n"
     ]
    }
   ],
   "source": [
    "key = 11\n",
    "print('The key: ', key)\n",
    "\n",
    "# create the cipher object, this is my toy example of a cipher\n",
    "cipher = AotWCipher(key)\n",
    "\n",
    "# get our training data\n",
    "text, ciphertext = get_random_pairs(cipher, 250000, 5, 10, key)\n",
    "\n",
    "# this should just be the length we asked for\n",
    "print('Generated {0} encrpyted sequences.'.format(len(ciphertext)))\n",
    "\n",
    "# print 3 examples\n",
    "for i in range(1000,1003):\n",
    "    print('Example of origin and encrypted text:')\n",
    "    print('\\t{0}'.format(text[i]))\n",
    "    print('\\t{0}'.format(ciphertext[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's test the cipher object**\n",
    "\n",
    "Since this isn't a standard cipher let's just demonstrate what it does. Basically it just int encodes your text, and can decode the same. I'll encode a few sample sequences and see if we can decode the original message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: hi there   Became: [ 80  41  62  36 137  94  79 113]\n",
      "Text: metallica   Became: [ 36  42  29  90 135 125  56  87  65]\n",
      "Text: easter bunny   Became: [ 47  59  91  36 104 116  53 140  63  75  80  99]\n",
      "\n",
      "Text: [ 80  41  62  36 137  94  79 113]   Became: hi there\n",
      "Text: [ 36  42  29  90 135 125  56  87  65]   Became: metallica\n",
      "Text: [ 47  59  91  36 104 116  53 140  63  75  80  99]   Became: easter bunny\n"
     ]
    }
   ],
   "source": [
    "# create a few test strings\n",
    "sample_1 = 'hi there'\n",
    "sample_2 = 'metallica'\n",
    "sample_3 = 'easter bunny'\n",
    "# encode the strings with the cipher\n",
    "encoded_1 = encode(cipher, sample_1)\n",
    "encoded_2 = encode(cipher, sample_2)\n",
    "encoded_3 = encode(cipher, sample_3)\n",
    "# print what the original and encoded strings look like\n",
    "print(f'Text: {sample_1}   Became: {encoded_1}')\n",
    "print(f'Text: {sample_2}   Became: {encoded_2}')\n",
    "print(f'Text: {sample_3}   Became: {encoded_3}\\n')\n",
    "# now decode the encoded strings\n",
    "decoded_1 = ''.join(decode(cipher, encoded_1))\n",
    "decoded_2 = ''.join(decode(cipher, encoded_2))\n",
    "decoded_3 = ''.join(decode(cipher, encoded_3))\n",
    "# and print what the transformation was\n",
    "print(f'Text: {encoded_1}   Became: {decoded_1}')\n",
    "print(f'Text: {encoded_2}   Became: {decoded_2}')\n",
    "print(f'Text: {encoded_3}   Became: {decoded_3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ok, now to carry on generating the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "alphabet = get_alphabet()\n",
    "# determine what the unique chars are in the ciphertext\n",
    "ct_alphabet = set()\n",
    "for line in ciphertext:\n",
    "    [ct_alphabet.add(c) for c in line]\n",
    "\n",
    "# figure out the length of the longest sequences\n",
    "max_ct_len = max([len(line) for line in ciphertext])\n",
    "max_input_len = max([len(line) for line in text])\n",
    "\n",
    "# int encode with a lookup dict - reserve zero to be used as the padding \n",
    "ctalph_to_idx = { char: i+1 for i, char in enumerate(ct_alphabet) }\n",
    "idx_to_ctalph = { ctalph_to_idx[key]: key for key in ctalph_to_idx.keys() }\n",
    "\n",
    "alph_to_idx = { char: i+1 for i, char in enumerate(alphabet) }\n",
    "idx_to_alph = { alph_to_idx[key]: key for key in alph_to_idx.keys() }\n",
    "\n",
    "# int encode all the input chars\n",
    "encoded_text_lines = []\n",
    "for i, line in enumerate(text):\n",
    "    new_line = np.zeros((len(line), ))\n",
    "    for j, char in enumerate(line):\n",
    "        new_line[j] = alph_to_idx[char]\n",
    "    encoded_text_lines.append(new_line)\n",
    "\n",
    "# apply zero padding to the input sequences \n",
    "np_text = pad_sequences(encoded_text_lines, maxlen=max_input_len, padding='pre')\n",
    "\n",
    "# pad the ciphertext sequences as well\n",
    "np_ciphertext = pad_sequences(ciphertext, maxlen=max_input_len, padding='pre')\n",
    "\n",
    "# determine the number of characters used in our input and output sequences\n",
    "alphabet_len = len(alphabet) +1 # +1 to accommodate the padding char\n",
    "ct_alphabet_len = len(ct_alphabet) +1 # +1 here too\n",
    "\n",
    "# now one-hot-encode the target, it's been int encoded until now\n",
    "y = encode_output(np_text, alphabet_len, alph_to_idx)\n",
    "X = np_ciphertext\n",
    "\n",
    "input_seq_len = X.shape[1]\n",
    "output_seq_len = y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train!**\n",
    "\n",
    "With the data ready for the model, we can train! This is a relatively small seq2seq model that starts with an embedding layer that takes a small embedding dimension. You could one-hot-encode the input and do away with the embedding too, it's just something I wanted to try. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 9, 3)              447       \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 512)               532480    \n",
      "_________________________________________________________________\n",
      "repeat_vector_5 (RepeatVecto (None, 9, 512)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 9, 256)            787456    \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 9, 78)             20046     \n",
      "=================================================================\n",
      "Total params: 1,340,429\n",
      "Trainable params: 1,340,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jarre\\Anaconda3\\envs\\ML 2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200000 samples, validate on 50000 samples\n",
      "Epoch 1/65\n",
      " - 19s - loss: 3.4449 - accuracy: 0.2308 - val_loss: 3.3605 - val_accuracy: 0.2325\n",
      "Epoch 2/65\n",
      " - 18s - loss: 3.2874 - accuracy: 0.2377 - val_loss: 3.2423 - val_accuracy: 0.2379\n",
      "Epoch 3/65\n",
      " - 19s - loss: 3.2104 - accuracy: 0.2466 - val_loss: 3.1714 - val_accuracy: 0.2497\n",
      "Epoch 4/65\n",
      " - 18s - loss: 3.1270 - accuracy: 0.2580 - val_loss: 3.0744 - val_accuracy: 0.2671\n",
      "Epoch 5/65\n",
      " - 18s - loss: 3.0565 - accuracy: 0.2680 - val_loss: 3.0002 - val_accuracy: 0.2802\n",
      "Epoch 6/65\n",
      " - 18s - loss: 2.9614 - accuracy: 0.2846 - val_loss: 2.9112 - val_accuracy: 0.2964\n",
      "Epoch 7/65\n",
      " - 18s - loss: 2.8761 - accuracy: 0.2992 - val_loss: 3.0642 - val_accuracy: 0.2529\n",
      "Epoch 8/65\n",
      " - 18s - loss: 2.7867 - accuracy: 0.3268 - val_loss: 2.7213 - val_accuracy: 0.3520\n",
      "Epoch 9/65\n",
      " - 18s - loss: 2.6818 - accuracy: 0.3610 - val_loss: 2.6351 - val_accuracy: 0.3718\n",
      "Epoch 10/65\n",
      " - 18s - loss: 2.6059 - accuracy: 0.3722 - val_loss: 2.5576 - val_accuracy: 0.3820\n",
      "Epoch 11/65\n",
      " - 18s - loss: 2.5183 - accuracy: 0.3872 - val_loss: 2.4839 - val_accuracy: 0.3908\n",
      "Epoch 12/65\n",
      " - 18s - loss: 2.4984 - accuracy: 0.3837 - val_loss: 2.4328 - val_accuracy: 0.3969\n",
      "Epoch 13/65\n",
      " - 18s - loss: 2.3807 - accuracy: 0.4061 - val_loss: 2.3310 - val_accuracy: 0.4164\n",
      "Epoch 14/65\n",
      " - 19s - loss: 2.2678 - accuracy: 0.4343 - val_loss: 2.2085 - val_accuracy: 0.4479\n",
      "Epoch 15/65\n",
      " - 18s - loss: 2.2030 - accuracy: 0.4535 - val_loss: 2.1158 - val_accuracy: 0.4764\n",
      "Epoch 16/65\n",
      " - 18s - loss: 2.0593 - accuracy: 0.4881 - val_loss: 2.0095 - val_accuracy: 0.5012\n",
      "Epoch 17/65\n",
      " - 19s - loss: 1.9711 - accuracy: 0.5113 - val_loss: 2.4148 - val_accuracy: 0.3941\n",
      "Epoch 18/65\n",
      " - 18s - loss: 1.8490 - accuracy: 0.5396 - val_loss: 1.7723 - val_accuracy: 0.5625\n",
      "Epoch 19/65\n",
      " - 18s - loss: 1.7112 - accuracy: 0.5783 - val_loss: 1.6545 - val_accuracy: 0.5925\n",
      "Epoch 20/65\n",
      " - 18s - loss: 1.5944 - accuracy: 0.6055 - val_loss: 1.5417 - val_accuracy: 0.6177\n",
      "Epoch 21/65\n",
      " - 18s - loss: 1.5981 - accuracy: 0.6064 - val_loss: 1.4586 - val_accuracy: 0.6403\n",
      "Epoch 22/65\n",
      " - 18s - loss: 1.4083 - accuracy: 0.6532 - val_loss: 1.3647 - val_accuracy: 0.6629\n",
      "Epoch 23/65\n",
      " - 18s - loss: 1.3166 - accuracy: 0.6768 - val_loss: 1.2804 - val_accuracy: 0.6864\n",
      "Epoch 24/65\n",
      " - 18s - loss: 1.2621 - accuracy: 0.6904 - val_loss: 1.1979 - val_accuracy: 0.7107\n",
      "Epoch 25/65\n",
      " - 18s - loss: 1.1522 - accuracy: 0.7238 - val_loss: 1.1151 - val_accuracy: 0.7333\n",
      "Epoch 26/65\n",
      " - 18s - loss: 1.0714 - accuracy: 0.7475 - val_loss: 1.0350 - val_accuracy: 0.7583\n",
      "Epoch 27/65\n",
      " - 18s - loss: 1.0526 - accuracy: 0.7544 - val_loss: 0.9999 - val_accuracy: 0.7679\n",
      "Epoch 28/65\n",
      " - 18s - loss: 0.9327 - accuracy: 0.7871 - val_loss: 0.8997 - val_accuracy: 0.7944\n",
      "Epoch 29/65\n",
      " - 18s - loss: 0.8602 - accuracy: 0.8056 - val_loss: 0.8326 - val_accuracy: 0.8123\n",
      "Epoch 30/65\n",
      " - 18s - loss: 0.8174 - accuracy: 0.8166 - val_loss: 0.7716 - val_accuracy: 0.8310\n",
      "Epoch 31/65\n",
      " - 18s - loss: 0.7372 - accuracy: 0.8398 - val_loss: 0.7131 - val_accuracy: 0.8455\n",
      "Epoch 32/65\n",
      " - 18s - loss: 0.7062 - accuracy: 0.8475 - val_loss: 0.6675 - val_accuracy: 0.8581\n",
      "Epoch 33/65\n",
      " - 18s - loss: 0.6388 - accuracy: 0.8640 - val_loss: 0.6183 - val_accuracy: 0.8679\n",
      "Epoch 34/65\n",
      " - 18s - loss: 0.5914 - accuracy: 0.8735 - val_loss: 0.5718 - val_accuracy: 0.8762\n",
      "Epoch 35/65\n",
      " - 18s - loss: 0.5430 - accuracy: 0.8826 - val_loss: 0.5225 - val_accuracy: 0.8858\n",
      "Epoch 36/65\n",
      " - 18s - loss: 0.5283 - accuracy: 0.8836 - val_loss: 0.4808 - val_accuracy: 0.8954\n",
      "Epoch 37/65\n",
      " - 18s - loss: 0.4528 - accuracy: 0.9026 - val_loss: 0.4331 - val_accuracy: 0.9082\n",
      "Epoch 38/65\n",
      " - 18s - loss: 0.4057 - accuracy: 0.9150 - val_loss: 0.3887 - val_accuracy: 0.9198\n",
      "Epoch 39/65\n",
      " - 18s - loss: 0.3823 - accuracy: 0.9205 - val_loss: 0.3556 - val_accuracy: 0.9283\n",
      "Epoch 40/65\n",
      " - 18s - loss: 0.3295 - accuracy: 0.9339 - val_loss: 0.3170 - val_accuracy: 0.9363\n",
      "Epoch 41/65\n",
      " - 18s - loss: 0.2999 - accuracy: 0.9400 - val_loss: 0.2899 - val_accuracy: 0.9416\n",
      "Epoch 42/65\n",
      " - 18s - loss: 0.2724 - accuracy: 0.9450 - val_loss: 0.2629 - val_accuracy: 0.9463\n",
      "Epoch 43/65\n",
      " - 18s - loss: 0.2442 - accuracy: 0.9504 - val_loss: 0.2359 - val_accuracy: 0.9522\n",
      "Epoch 44/65\n",
      " - 18s - loss: 0.2418 - accuracy: 0.9499 - val_loss: 0.6032 - val_accuracy: 0.8281\n",
      "Epoch 45/65\n",
      " - 18s - loss: 0.2031 - accuracy: 0.9592 - val_loss: 0.1822 - val_accuracy: 0.9640\n",
      "Epoch 46/65\n",
      " - 18s - loss: 0.1667 - accuracy: 0.9680 - val_loss: 0.1577 - val_accuracy: 0.9696\n",
      "Epoch 47/65\n",
      " - 18s - loss: 0.1439 - accuracy: 0.9728 - val_loss: 0.1382 - val_accuracy: 0.9736\n",
      "Epoch 48/65\n",
      " - 18s - loss: 0.1231 - accuracy: 0.9768 - val_loss: 0.1186 - val_accuracy: 0.9774\n",
      "Epoch 49/65\n",
      " - 18s - loss: 0.1054 - accuracy: 0.9804 - val_loss: 0.0994 - val_accuracy: 0.9817\n",
      "Epoch 50/65\n",
      " - 18s - loss: 0.0894 - accuracy: 0.9837 - val_loss: 0.0856 - val_accuracy: 0.9842\n",
      "Epoch 51/65\n",
      " - 18s - loss: 0.0746 - accuracy: 0.9872 - val_loss: 0.0697 - val_accuracy: 0.9884\n",
      "Epoch 52/65\n",
      " - 18s - loss: 0.1178 - accuracy: 0.9766 - val_loss: 0.1179 - val_accuracy: 0.9749\n",
      "Epoch 53/65\n",
      " - 18s - loss: 0.0580 - accuracy: 0.9918 - val_loss: 0.0515 - val_accuracy: 0.9932\n",
      "Epoch 54/65\n",
      " - 18s - loss: 0.0457 - accuracy: 0.9944 - val_loss: 0.0437 - val_accuracy: 0.9949\n",
      "Epoch 55/65\n",
      " - 18s - loss: 0.0391 - accuracy: 0.9958 - val_loss: 0.0386 - val_accuracy: 0.9957\n",
      "Epoch 56/65\n",
      " - 18s - loss: 0.0340 - accuracy: 0.9966 - val_loss: 0.0329 - val_accuracy: 0.9968\n",
      "Epoch 57/65\n",
      " - 18s - loss: 0.0290 - accuracy: 0.9975 - val_loss: 0.0285 - val_accuracy: 0.9975\n",
      "Epoch 58/65\n",
      " - 18s - loss: 0.0250 - accuracy: 0.9979 - val_loss: 0.0241 - val_accuracy: 0.9979\n",
      "Epoch 59/65\n",
      " - 18s - loss: 0.0214 - accuracy: 0.9983 - val_loss: 0.0213 - val_accuracy: 0.9981\n",
      "Epoch 60/65\n",
      " - 18s - loss: 0.0185 - accuracy: 0.9985 - val_loss: 0.0175 - val_accuracy: 0.9984\n",
      "Epoch 61/65\n",
      " - 18s - loss: 0.0155 - accuracy: 0.9987 - val_loss: 0.0161 - val_accuracy: 0.9985\n",
      "Epoch 62/65\n",
      " - 18s - loss: 0.0993 - accuracy: 0.9811 - val_loss: 0.0202 - val_accuracy: 0.9981\n",
      "Epoch 63/65\n",
      " - 18s - loss: 0.0152 - accuracy: 0.9988 - val_loss: 0.0145 - val_accuracy: 0.9986\n",
      "Epoch 64/65\n",
      " - 18s - loss: 0.0124 - accuracy: 0.9989 - val_loss: 0.0128 - val_accuracy: 0.9987\n",
      "Epoch 65/65\n",
      " - 18s - loss: 0.0112 - accuracy: 0.9989 - val_loss: 0.0115 - val_accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "model = get_model(alphabet_len, ct_alphabet_len, input_seq_len, output_seq_len, 3)\n",
    "epochs=65\n",
    "batch_size = 512\n",
    "model.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=2)\n",
    "model.save('./decode_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pretty cool, the LSTM had no problem learning the simple cipher**\n",
    "\n",
    "Is it any suprise the LSTM could learn this simple cipher? Not really. I read a blog article once about project to make a LSTM to learn the Enigma cipher, so it's really no suprise this simple cipher is learned easily. You can check out the article about the enigma here if you are interested.  https://greydanus.github.io/2017/01/07/enigma-rnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now as a test of the trained model**\n",
    "\n",
    "Let's encode some text with the cipher and see if the neural net can decode it! We'll choose some sample text to encode and then decode it with the neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jarre\\Anaconda3\\envs\\ML 2.0\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"good day!\" became [ 41  27  51 108 100 129  74 119  78]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "# load up the trained model\n",
    "model = load_model('./decode_model.h5')\n",
    "\n",
    "# create the ciphertext we would like to decode\n",
    "text = 'good day!'\n",
    "ciphertext = encode(cipher, text)\n",
    "print(f'\"{text}\" became {ciphertext}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ok! This is getting exciting now. The text is now encrypted.**\n",
    "\n",
    "Let's use the neural net to decrypt the sequence and see what happens! Before comparing cipher vs. neural net, let's get the prediction from the neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the array containing the prediction\n",
      " (1, 9, 78)\n",
      "\n",
      "The decoded text is the index of the most probable character at each timestep\n",
      " [ 7 15 15  4 63  4  1 25 65]\n",
      "\n",
      "We can check the probabilities of each predicted char\n",
      " [[[0.99757487]\n",
      "  [0.993335  ]\n",
      "  [0.9839482 ]\n",
      "  [0.9900725 ]\n",
      "  [0.9998447 ]\n",
      "  [0.9561768 ]\n",
      "  [0.9754199 ]\n",
      "  [0.97674584]\n",
      "  [0.979807  ]]]\n"
     ]
    }
   ],
   "source": [
    "# add a dimension by creating a list so padding works\n",
    "ciphertext = [ciphertext]\n",
    "# the source text is already the max length, so there is no padding actually applied\n",
    "np_ciphertext = pad_sequences(ciphertext, maxlen=len(text), padding='pre')\n",
    "\n",
    "prediction = model.predict(np_ciphertext)\n",
    "# the shape of the prediction is (batch, time_steps, features)\n",
    "print('Shape of the array containing the prediction\\n', prediction.shape)\n",
    "\n",
    "predicted_chars = np.argmax(prediction, axis=2)\n",
    "print('\\nThe decoded text is the index of the most probable character at each timestep\\n',predicted_chars[0])\n",
    "\n",
    "probabilities = np.take_along_axis(prediction, np.expand_dims(predicted_chars, axis=-1), axis=-1)\n",
    "print('\\nWe can check the probabilities of each predicted char\\n', probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural net decoded text\n",
      "good day!\n",
      "\n",
      "Cipher decoded text\n",
      "good day!\n"
     ]
    }
   ],
   "source": [
    "neural_net_decoded = ''.join(cipher.int_decode(predicted_chars[0] -1))\n",
    "cipher_decoded = ''.join(decode(cipher, ciphertext[0]))\n",
    "\n",
    "print(f'\\nNeural net decoded text\\n{neural_net_decoded}')\n",
    "print(f'\\nCipher decoded text\\n{cipher_decoded}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So cool!**\n",
    "\n",
    "**We were able to demonstrate that our seq2seq LSTM, with a learned function, can produce the same output as the hand coded function.**\n",
    "\n",
    "This concludes the project. Thanks for following along! Be 1% better every day. Keep on learning friends. :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
